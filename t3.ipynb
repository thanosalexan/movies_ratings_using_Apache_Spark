{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076babe8",
   "metadata": {},
   "source": [
    "# Course         : Big Data Systems and Architectures \n",
    "\n",
    "# Assignment : Spark & Airflow \n",
    "\n",
    "# Task3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2688388",
   "metadata": {},
   "source": [
    "Student Name:Athanasios Alexandris\n",
    "\n",
    "Student id : p2822202\n",
    "\n",
    "Msc : Business Analytics PT, AUEB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb9300",
   "metadata": {},
   "source": [
    "As first steps in Task3, we created a SparkSession using the SparkSession.builder API with application name 'q3'. The getOrCreate() method is called to either get an existing SparkSession with the same application name or create a new one if it doesn't exist. So we created a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b714ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5d1dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 12:37:36 WARN Utils: Your hostname, MacBook-Pro-4.local resolves to a loopback address: 127.0.0.1; using 192.168.23.32 instead (on interface en0)\n",
      "23/04/14 12:37:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 12:37:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('q3').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5d7e9",
   "metadata": {},
   "source": [
    "Next we used the read.json() method to read the JSON file that contains our dataset and load it into a DataFrame in Spark. The dataframe is being cached to memory, allowing Spark to access it quickly without having to read it from the JSON file again. The cache() does not immediately cache the data, but instead marks it for caching. The data will be cached in memory the first time an action operation (e.g., show(), count(), etc.) is performed on the DataFrame. Also we displayed the first 20 rows of the dataset. Finally we decided to drop the rows that contain null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b191b140",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('/Users/thanosalexandris/Downloads/movie.json', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9a9549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------+-------+--------------------+--------------------+------------+---------+----+\n",
      "|              actors|           countries|         description|           directors|               genre|            imdb_url|             img_url|           languages|metascore|rating|runtime|             tagline|               title|users_rating|    votes|year|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------+-------+--------------------+--------------------+------------+---------+----+\n",
      "|[Timoth√©e Chalame...|               [USA]|A young couple ar...|       [Woody Allen]|   [Comedy, Romance]|https://www.imdb....|https://m.media-a...|           [English]|       44| PG-13| 92 min|                null|A Rainy Day in Ne...|         6.6|   21,903|2019|\n",
      "|[Emilia Clarke, H...|               [USA]|Creepy, terrifyin...|[Michael Escobedo...|  [Horror, Thriller]|https://www.imdb....|https://m.media-a...|           [English]|     null|    18| 91 min|When it comes to ...|       Murder Manual|         2.4|      192|2020|\n",
      "|[Matthew Broderic...|               [USA]|A high school wis...|       [John Hughes]|            [Comedy]|https://www.imdb....|https://m.media-a...|   [English, German]|       61| PG-13|103 min|Because life is t...|Ferris Bueller's ...|         7.8|  308,847|1986|\n",
      "|[Robert De Niro, ...|               [USA]|A convicted rapis...|   [Martin Scorsese]|   [Crime, Thriller]|https://www.imdb....|https://m.media-a...|           [English]|       73|     R|128 min|There is nothing ...|           Cape Fear|         7.3|  165,628|1991|\n",
      "|[Lindsay Lohan, R...|       [USA, Canada]|Cady Heron is a h...|       [Mark Waters]|            [Comedy]|https://www.imdb....|https://m.media-a...|[English, German,...|       66| PG-13| 97 min|Survival of the R...|          Mean Girls|         7.0|  320,492|2004|\n",
      "|[Sophia Lillis, S...|[Canada, Ireland,...|A long time ago i...|        [Oz Perkins]|[Fantasy, Horror,...|https://www.imdb....|https://m.media-a...|           [English]|       64| PG-13| 87 min|  Follow the crumbs.|     Gretel & Hansel|         5.3|   15,051|2020|\n",
      "|[Chris Pratt, Bry...|               [USA]|When the island's...|       [J.A. Bayona]|[Action, Adventur...|https://www.imdb....|https://m.media-a...|  [English, Russian]|       51| PG-13|128 min|Off the Island. I...|Jurassic World: F...|         6.2|  250,190|2018|\n",
      "|[Robert Downey Jr...|               [USA]|Earth's mightiest...|       [Joss Whedon]|[Action, Adventur...|https://www.imdb....|https://m.media-a...|[English, Russian...|       69| PG-13|143 min|  Avengers Assemble!|        The Avengers|         8.0|1,233,746|2012|\n",
      "|[Matt Damon, Ben ...|               [USA]|Will Hunting, a j...|      [Gus Van Sant]|    [Drama, Romance]|https://www.imdb....|https://m.media-a...|           [English]|       70|     R|126 min|Wildly charismati...|   Good Will Hunting|         8.3|  826,970|1997|\n",
      "|[Keir Dullea, Gar...|           [UK, USA]|After discovering...|   [Stanley Kubrick]| [Adventure, Sci-Fi]|https://www.imdb....|https://m.media-a...|  [English, Russian]|       84|     G|149 min|50 Years Ago One ...|2001: A Space Ody...|         8.3|  580,491|1968|\n",
      "|[Al Pacino, Steve...|               [USA]|In 1980 Miami, a ...|    [Brian De Palma]|      [Crime, Drama]|https://www.imdb....|https://m.media-a...|  [English, Spanish]|       65|     R|170 min|The world is your...|            Scarface|         8.3|  712,283|1983|\n",
      "|[Jason London, Jo...|               [USA]|The adventures of...| [Richard Linklater]|            [Comedy]|https://www.imdb....|https://m.media-a...|           [English]|       78|     R|102 min|         Weed rules.|  Dazed and Confused|         7.6|  158,876|1993|\n",
      "|[John Ralston, Th...|[Canada, Germany,...|A young genius ac...|[Anthony Scott Bu...|[Drama, Horror, M...|https://www.imdb....|https://m.media-a...|           [English]|       45| PG-13| 90 min|Houses Are As Hau...|           Our House|         5.3|    5,563|2018|\n",
      "|[Matthew Modine, ...|           [UK, USA]|A pragmatic U.S. ...|   [Stanley Kubrick]|        [Drama, War]|https://www.imdb....|https://m.media-a...|[English, Vietnam...|       76|     R|116 min|Acclaimed by crit...|   Full Metal Jacket|         8.3|  650,539|1987|\n",
      "|[Daniel Radcliffe...|  [UK, USA, Germany]|An ancient prophe...|    [Chris Columbus]|[Adventure, Famil...|https://www.imdb....|https://m.media-a...|           [English]|       63|    PG|161 min|\"Dobby has come t...|Harry Potter and ...|         7.4|  529,173|2002|\n",
      "|[Clint Eastwood, ...|      [Germany, USA]|Disgruntled Korea...|    [Clint Eastwood]|             [Drama]|https://www.imdb....|https://m.media-a...|    [English, Hmong]|       72|     R|116 min|                null|         Gran Torino|         8.1|  701,410|2008|\n",
      "|[Frances McDorman...|           [UK, USA]|A mother personal...|   [Martin McDonagh]|[Comedy, Crime, D...|https://www.imdb....|https://m.media-a...|           [English]|       88|     R|115 min|                null|Three Billboards ...|         8.2|  401,685|2017|\n",
      "|[Paul Sanchez, La...|               [USA]|A FedEx executive...|   [Robert Zemeckis]|[Adventure, Drama...|https://www.imdb....|https://m.media-a...|  [English, Russian]|       73| PG-13|143 min|At the edge of th...|           Cast Away|         7.8|  504,512|2000|\n",
      "|[Ewan McGregor, N...|               [USA]|Three years into ...|      [George Lucas]|[Action, Adventur...|https://www.imdb....|https://m.media-a...|           [English]|       68| PG-13|140 min|The saga is compl...|Star Wars: Episod...|         7.5|  688,367|2005|\n",
      "|[Sandra Bullock, ...|               [USA]|Five years after ...|      [Susanne Bier]|[Drama, Horror, S...|https://www.imdb....|https://m.media-a...|           [English]|       51|     R|124 min|Never Lose Sight ...|            Bird Box|         6.6|  260,466|2018|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------+-------+--------------------+--------------------+------------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b04ef0",
   "metadata": {},
   "source": [
    "Next, we decided to create a new dataframe, that contains only the columns that we are interested in. For the 'users rating' column we transform it to type double, for the 'metascore' column we transform it to integer, for the 'runtime' column we split the column with space keeping only the first field and tranform it to integer. For te columns 'genre' and 'languages' we used the expr() method to keep only the first field for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd7844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1ea978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.select(df[\"users_rating\"].cast(\"double\"),df[\"metascore\"].cast(\"integer\"),(split(\"runtime\", \" \").getItem(0).cast(\"integer\")).alias(\"runtime\"),expr(\"genre[0]\").alias(\"genre\"),expr(\"languages[0]\").alias(\"languages\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe8d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+---------+---------+\n",
      "|users_rating|metascore|runtime|    genre|languages|\n",
      "+------------+---------+-------+---------+---------+\n",
      "|         6.6|       44|     92|   Comedy|  English|\n",
      "|         2.4|     null|     91|   Horror|  English|\n",
      "|         7.8|       61|    103|   Comedy|  English|\n",
      "|         7.3|       73|    128|    Crime|  English|\n",
      "|         7.0|       66|     97|   Comedy|  English|\n",
      "|         5.3|       64|     87|  Fantasy|  English|\n",
      "|         6.2|       51|    128|   Action|  English|\n",
      "|         8.0|       69|    143|   Action|  English|\n",
      "|         8.3|       70|    126|    Drama|  English|\n",
      "|         8.3|       84|    149|Adventure|  English|\n",
      "|         8.3|       65|    170|    Crime|  English|\n",
      "|         7.6|       78|    102|   Comedy|  English|\n",
      "|         5.3|       45|     90|    Drama|  English|\n",
      "|         8.3|       76|    116|    Drama|  English|\n",
      "|         7.4|       63|    161|Adventure|  English|\n",
      "|         8.1|       72|    116|    Drama|  English|\n",
      "|         8.2|       88|    115|   Comedy|  English|\n",
      "|         7.8|       73|    143|Adventure|  English|\n",
      "|         7.5|       68|    140|   Action|  English|\n",
      "|         6.6|       51|    124|    Drama|  English|\n",
      "|         5.5|       54|    102|Biography|  English|\n",
      "|         7.1|       82|    109|   Comedy|  English|\n",
      "|         7.5|       54|    108|   Comedy|  Italian|\n",
      "|         8.2|       72|    135|Biography|  English|\n",
      "|         8.1|       85|     98|    Crime|  English|\n",
      "|         7.6|       80|    110|    Drama|  English|\n",
      "|         7.6|       63|    158|    Drama|  English|\n",
      "|         6.9|       67|    105|    Drama|  English|\n",
      "|         7.6|       76|    113|   Comedy|  English|\n",
      "|         7.2|       65|    101|   Action|  English|\n",
      "|         5.4|       35|    102|   Action|  English|\n",
      "|         6.5|       54|    142|   Action|  English|\n",
      "|         8.3|      100|    128|  Mystery|  English|\n",
      "|         5.6|     null|     97|   Action|  English|\n",
      "|         7.5|     null|     80|Animation|  English|\n",
      "|         8.1|       84|    117|   Action|  English|\n",
      "|         7.6|       56|    162|   Action|  English|\n",
      "|         7.5|       68|    131|Biography|  English|\n",
      "|         7.4|       64|    122|    Drama|  English|\n",
      "|         7.8|       84|    100|Animation|  English|\n",
      "|         6.0|       43|    114|   Action|  English|\n",
      "|         7.2|       51|    112|    Drama|  English|\n",
      "|         6.2|       78|     91|   Horror|  English|\n",
      "|         7.2|       86|    138|    Drama| Filipino|\n",
      "|         6.8|       38|    103|   Action|  English|\n",
      "|         6.6|       53|    140|   Action|  English|\n",
      "|         6.0|       46|    110|   Action|  English|\n",
      "|         7.4|       97|    110|   Comedy|  English|\n",
      "|         7.3|       25|    124|Biography|  English|\n",
      "|         7.1|       61|     93|   Comedy|  English|\n",
      "|         6.4|       36|     99|  Mystery|  English|\n",
      "|         5.8|       41|    131|   Action|  English|\n",
      "|         3.7|       28|    125|   Action|  English|\n",
      "|         6.9|       72|     98|   Comedy|  English|\n",
      "|         7.7|       74|    144|    Drama|  English|\n",
      "|         7.5|       43|    109|   Comedy|  English|\n",
      "|         6.5|       42|    110|   Horror|  English|\n",
      "|         7.7|       69|    107|Adventure|  English|\n",
      "|         7.9|       67|     97|    Drama|  English|\n",
      "|         6.2|       50|    108|   Comedy|  English|\n",
      "|         4.3|       18|     94|   Comedy|  English|\n",
      "|         7.0|       77|    108|    Drama|  English|\n",
      "|         6.6|       46|    149|  Mystery|  English|\n",
      "|         6.7|       50|    121|   Action|  English|\n",
      "|         6.4|       72|     91|   Comedy|  English|\n",
      "|         7.1|       68|    124|   Comedy|  English|\n",
      "|         6.1|       41|     90|   Comedy|  English|\n",
      "|         7.1|       60|     95|   Action|  English|\n",
      "|         7.1|       61|    130|   Action|  English|\n",
      "|         8.0|       59|    156|    Drama|  English|\n",
      "|         6.3|       57|     95|   Comedy|  English|\n",
      "|         7.9|       74|    105|    Drama|  English|\n",
      "|         5.8|       77|    113|Adventure|  English|\n",
      "|         7.1|       63|     91|    Drama|  English|\n",
      "|         6.8|       70|    100|    Drama|  English|\n",
      "|         5.3|       46|     96|   Horror|  English|\n",
      "|         8.1|       77|    101|    Drama|  English|\n",
      "|         6.6|       59|    114|   Action|  English|\n",
      "|         6.9|       52|     95|Animation|  English|\n",
      "|         6.1|       43|    115|   Action|  English|\n",
      "|         6.4|       65|     94|    Drama|  English|\n",
      "|         6.2|       42|    154|   Action|  English|\n",
      "|         7.8|       87|    130|   Action|  English|\n",
      "|         5.7|       57|    101|   Horror|  English|\n",
      "|         6.6|       44|    103|   Comedy|  English|\n",
      "|         7.3|       76|    138|    Drama|  English|\n",
      "|         5.1|       42|     93|   Action|  English|\n",
      "|         7.3|       62|     98|Animation|  English|\n",
      "|         7.9|       84|    132|    Drama|  English|\n",
      "|         6.4|       43|    108|   Comedy|  English|\n",
      "|         5.3|       43|    110|    Drama|  English|\n",
      "|         8.0|       95|     84|Animation|  English|\n",
      "|         7.8|       78|    154|    Drama|  English|\n",
      "|         6.8|       64|    113|Adventure|  English|\n",
      "|         7.3|       73|    104|   Comedy|  English|\n",
      "|         6.7|       59|    106|    Drama|  English|\n",
      "|         7.1|       77|    114|   Action|  English|\n",
      "|         6.7|       36|     98|   Horror|  English|\n",
      "|         5.6|       47|     97|   Comedy|  English|\n",
      "|         6.9|       53|    112|   Comedy|  English|\n",
      "|         6.8|       65|    112|    Crime|  English|\n",
      "|         7.0|       64|     91|   Comedy|  English|\n",
      "|         7.4|       68|    134|   Action|  English|\n",
      "|         7.0|       60|     98|   Action|  English|\n",
      "|         7.4|       56|    126|    Crime|  English|\n",
      "|         6.7|       44|    104|Adventure|  English|\n",
      "|         6.5|       50|    103|   Comedy|  English|\n",
      "|         6.7|       33|    100|   Action|  English|\n",
      "|         7.9|       75|    110|    Crime|  English|\n",
      "|         6.3|       46|    105|   Comedy|  English|\n",
      "|         5.9|       12|    104|   Comedy|  English|\n",
      "|         6.8|       46|    104|   Comedy|  English|\n",
      "|         7.0|       33|     94|   Comedy|  English|\n",
      "|         7.4|       34|    109|   Action|  English|\n",
      "|         7.5|       60|     97|   Comedy|  English|\n",
      "|         7.5|       82|    111|    Drama|  English|\n",
      "|         5.9|       62|    106|    Drama|  English|\n",
      "|         6.4|     null|    107|   Comedy|  English|\n",
      "|         4.7|       30|     98| Thriller|  English|\n",
      "|         6.7|       38|    137|    Crime|  English|\n",
      "|         7.6|       79|    130|   Action|  English|\n",
      "|         6.0|       52|    150|   Action|  English|\n",
      "|         6.3|       39|    129|   Action|  English|\n",
      "|         6.2|       41|    121|   Action|  English|\n",
      "|         6.8|       72|    132|Biography|  English|\n",
      "|         5.9|       60|     89|   Comedy|  English|\n",
      "|         6.3|       43|     96|   Comedy|  English|\n",
      "|         5.5|       45|     92|   Action|  English|\n",
      "|         6.2|       49|    103|   Horror|  English|\n",
      "|         7.7|       73|    108|   Action|  English|\n",
      "|         6.1|       53|    107|   Comedy|  English|\n",
      "|         6.4|       52|    131|   Action|  English|\n",
      "|         6.6|       47|    116|   Action|  English|\n",
      "|         6.6|       56|     96|   Action|  English|\n",
      "|         7.4|       76|    112|    Crime|  English|\n",
      "|         6.7|       62|    102|    Crime|  English|\n",
      "|         5.2|       42|    107|   Action|  English|\n",
      "|         6.2|       49|    109|   Action|  English|\n",
      "|         7.6|       82|     94|Biography|  English|\n",
      "|         6.2|       43|    109|   Action|  English|\n",
      "|         6.0|       60|    107|   Action|  English|\n",
      "|         7.1|       67|    111|   Comedy|  English|\n",
      "|         5.2|       35|    100|   Horror|  English|\n",
      "|         7.2|       61|    126|Adventure|  English|\n",
      "|         7.5|       82|     86|   Comedy|   French|\n",
      "|         5.6|       63|    125|    Drama|  English|\n",
      "|         7.5|       72|    103|   Action|  English|\n",
      "|         6.4|       66|     99|   Comedy|  English|\n",
      "|         6.2|       71|    100|   Comedy|  English|\n",
      "|         7.8|       75|    178|   Action|  English|\n",
      "|         7.4|     null|    119|    Crime|  English|\n",
      "|         5.8|       51|    102|   Action|  English|\n",
      "|         6.2|       38|     93|   Horror|  English|\n",
      "|         6.5|       58|     96|Adventure|  English|\n",
      "|         7.0|       71|    112|   Action|  English|\n",
      "|         6.6|       39|    126|   Comedy|  English|\n",
      "|         7.4|       67|     90|   Comedy|  English|\n",
      "|         7.7|       67|    113|   Action|  English|\n",
      "|         6.1|       58|     93|Animation|  English|\n",
      "|         7.1|       58|    105|   Action|  English|\n",
      "|         6.7|       29|    118|    Drama|  English|\n",
      "|         6.7|       37|     90|   Comedy|  English|\n",
      "|         6.2|       47|     90|   Comedy|  English|\n",
      "|         6.6|       59|     88|   Comedy|  English|\n",
      "|         7.3|       89|     84|   Comedy|  English|\n",
      "|         6.6|       40|    102|   Action|  English|\n",
      "|         6.5|       67|     89|   Comedy|  English|\n",
      "|         6.9|       77|     92|   Comedy|  English|\n",
      "|         7.0|       59|    126|   Action|  English|\n",
      "|         5.8|       34|    115|    Drama|  English|\n",
      "|         6.9|       62|    110|Biography|  English|\n",
      "|         6.3|     null|    107|   Action|  English|\n",
      "|         5.7|       19|    101|   Horror|  English|\n",
      "|         7.8|       71|    108|Biography|  English|\n",
      "|         7.1|       56|    127|Biography|  English|\n",
      "|         7.2|       67|     91|Adventure|  English|\n",
      "|         5.1|       23|    119|    Crime|  English|\n",
      "|         4.9|       39|     87|Animation|  English|\n",
      "|         6.8|       73|    122|    Crime|   Arabic|\n",
      "|         3.7|       24|     83|   Comedy|  English|\n",
      "|         7.8|       79|    119|Biography|  English|\n",
      "|         6.6|       39|    113|   Action|  English|\n",
      "|         7.1|       64|    127|    Crime|  English|\n",
      "|         6.2|       50|    116|   Action|  English|\n",
      "|         7.6|       80|    118|    Drama|  English|\n",
      "|         7.0|       51|     93|   Action|  English|\n",
      "|         6.6|       42|    100|   Comedy|  English|\n",
      "|         6.1|       51|    110|   Comedy|  English|\n",
      "|         6.3|       50|     97|Animation|  English|\n",
      "|         6.1|     null|    106|   Comedy|  English|\n",
      "|         6.6|       65|     98|   Comedy|  English|\n",
      "|         5.5|       39|     99|Adventure|  English|\n",
      "|         5.9|       67|    114|    Drama|  English|\n",
      "|         7.1|       59|    117|Animation|  English|\n",
      "|         6.1|       68|    122|   Comedy|  English|\n",
      "|         6.4|       37|    105|    Crime|  English|\n",
      "|         6.2|       62|    121|   Action|  English|\n",
      "|         6.7|       78|     79|Animation|  English|\n",
      "|         7.0|       43|    131|   Action|  English|\n",
      "|         6.3|       43|    108|    Drama|  English|\n",
      "+------------+---------+-------+---------+---------+\n",
      "only showing top 200 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a6feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0e8e6",
   "metadata": {},
   "source": [
    "As our goal is to create a regression model that makes predictions we had to train and evaluate the model we building, by splitting our dataset to train and test dataframes. The train dataframe contains 80% of random data the test dataset 20%.  We used randomSplit() method and we set a particular number in seed, so every time we rerun the command we take exactly the same split. Also we used cache() function to keep the train dataset in the memory for perfomans reasons, as it is much bigger than the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7468cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7232\n",
      "1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = df2.randomSplit([0.8, 0.2], seed=999)\n",
    "\n",
    "print(trainDF.cache().count()) # Cache because accessing training data multiple times\n",
    "\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9ecd1",
   "metadata": {},
   "source": [
    "\n",
    "Next we had to manipulate the features to be in the appropriate MLlib format. As we want to implement linear regression the features have to be in numeric format, so we had to tranform the categorical columns 'genre', 'languages', to numeric, by using the 'one hot encoding' aproach, that converts that converts categorical variables into a set of numeric variables that only take on values 0 and 1. For this task first we used the StringIndexer that converts a column of string values to a column of label indexes, and then OneHotEncoder that maps a column of category indices to a column of binary vectors, with at most one \"1\" in each row that indicates the category index for that row. Then we used the .fit() method to return a StringIndexerModel, that used to transform the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b944b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# We determine which of the columns are categorical.\n",
    "categoricalCols = [\"genre\", \"languages\"]\n",
    "\n",
    "# The following two lines are estimators. They return functions that we will later apply to transform the dataset.\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + \"Index\" for x in categoricalCols]).setHandleInvalid('keep') \n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categoricalCols]) \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b603e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+------+---------+----------+--------------+\n",
      "|users_rating|metascore|runtime| genre|languages|genreIndex|languagesIndex|\n",
      "+------------+---------+-------+------+---------+----------+--------------+\n",
      "|         1.4|       18|     79|Comedy|  English|       0.0|           0.0|\n",
      "|         1.9|        7|     91|Comedy|  English|       0.0|           0.0|\n",
      "|         1.9|        9|     88|Comedy|  English|       0.0|           0.0|\n",
      "|         1.9|       15|     87|Comedy|  English|       0.0|           0.0|\n",
      "|         2.0|       15|     90|Action|  English|       2.0|           0.0|\n",
      "+------------+---------+-------+------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexerModel = stringIndexer.fit(trainDF)\n",
    "stringIndexerModel.transform(trainDF).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a64598",
   "metadata": {},
   "source": [
    "Then we used the 'VectorAssembler' transformer to create a single vector column from a list of columns, as the MLlib algorithm we are using requires a single features column as input. Each row in this column contains a vector of data points corresponding to the set of features used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283708d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = [\"metascore\", \"runtime\"]\n",
    "assemblerInputs = [c + \"OHE\" for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3cc0e",
   "metadata": {},
   "source": [
    "Next we defined the linear regression model that we use, defining the response column and the features data and seting a small number in regParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21355ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af6744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"users_rating\", regParam=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d24388",
   "metadata": {},
   "source": [
    "Next we defined a pipeline (ordered list of transformers and estimators) with the same steps that we implemented to the train dataset, to apply the same automate transformations to the test dataset. Then we used the pipeline.fit() method that returns a PipelineModel, which is a transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ffd90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/14 12:37:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/14 12:37:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/04/14 12:38:00 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline based on the stages created in previous steps.\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, vecAssembler, lr])\n",
    "\n",
    "# Define the pipeline model.\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Apply the pipeline model to the test dataset to classify the respective samples.\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10479f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------+\n",
      "|            features|users_rating|       prediction|\n",
      "+--------------------+------------+-----------------+\n",
      "|(57,[1,18,55,56],...|         1.8|4.137592268247825|\n",
      "|(57,[2,18,55,56],...|         2.1|5.370812849284812|\n",
      "|(57,[0,18,55,56],...|         2.2|5.024887038983677|\n",
      "|(57,[2,18,55,56],...|         2.5|4.789723958889092|\n",
      "|(57,[0,18,55,56],...|         2.5|5.326513549594811|\n",
      "+--------------------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.select(\"features\", \"users_rating\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871505f",
   "metadata": {},
   "source": [
    "To evaluate our model we used the RegressionEvaluator(), defining the predictions and the true labels, and setting as metring the R-Squared to measure the goodness of fit of the model. The Rsquared of our model is 0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4378b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared = 0.530499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 19:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"users_rating\",metricName=\"r2\")\n",
    "print(\"Rsquared = %g\" % evaluator.evaluate(predDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f016d",
   "metadata": {},
   "source": [
    "Finally we used ParamGridBuilder and CrossValidator to tune the modelusing three values for both regParam and  elasticNetParam, for a total of 9 hyperparameter combinations for CrossValidator to examine. We created a 3-fold cross validator, that automatically tracks all of the runs using MLflow. We used the pipeline we created as the estimator and MLlib  automatically tracks trials in MLflow. Then we fit the cross validator to our train data set to return the best model found from the cross validation, and then we used that model to make predictions on the test dataset. The Rsquared of the best model of the cross validation is 0.5321."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60a7638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared: 0.5321272552009226\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .build())\n",
    "\n",
    "# Create a 3-fold CrossValidator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3, parallelism = 4)\n",
    "\n",
    "# Run cross validations. This step takes a few minutes and returns the best model found from the cross validation.\n",
    "cvModel = cv.fit(trainDF)\n",
    "\n",
    "# Use the model identified by the cross-validation to make predictions on the test dataset\n",
    "cvPredDF = cvModel.transform(testDF)\n",
    "\n",
    "# Evaluate the model's performance based on area under the ROC curve and accuracy \n",
    "print(f\"Rsquared: {evaluator.evaluate(cvPredDF)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55002f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4ba27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8d863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
